# Система анализа состояния дорожного покрытия

## Описание проекта
Веб-приложение для автоматизированного анализа состояния дорожного покрытия с применением компьютерного зрения и искусственного интеллекта. Система позволяет выявлять и классифицировать дефекты по изображениям и видеозаписям, а также формировать экспертные рекомендации по ремонту.

## Основные возможности
- Загрузка изображений и видео дорожного покрытия через веб-интерфейс
- Автоматическая детекция и классификация дефектов с помощью обученной нейросети YOLO
- Использование расширенных аугментаций данных (геометрические, цветовые, комбинированные) при обучении модели для повышения устойчивости и качества детекции
- Поддержка 10 типов дефектов:
  1. D00 — Продольные трещины
  2. D01 — Подтип продольных трещин
  3. D10 — Поперечные трещины
  4. D11 — Подтип поперечных трещин
  5. D20 — Сетчатые трещины
  6. D40 — Выбоины
  7. D43 — Большие выбоины
  8. D44 — Глубокие выбоины
  9. D50 — Колеи, деформации, впадины
  10. Repair area — Зона ремонта
- Визуализация результатов: аннотированные изображения/видео с выделенными дефектами
- Хранение истории загрузок и результатов для каждого пользователя
- Генерация экспертных текстовых рекомендаций по ремонту с помощью GigaChat API
- Личный кабинет пользователя

## Почему и как я выбирал аугментации для обучения модели
Для повышения устойчивости и обобщающей способности модели YOLO я осознанно подошёл к выбору аугментаций. Были выбраны три класса аугментаций:
- **Геометрические** (вращение, сдвиг, масштабирование, shear, флипы), чтобы имитировать разные ракурсы и положения дефектов на дороге, а также компенсировать возможные ошибки съёмки.
- **Цветовые** (изменение оттенка, насыщенности, яркости), чтобы модель не зависела от погодных условий, времени суток и особенностей камер.
- **Комбинированные** (mosaic, mixup), чтобы повысить разнообразие обучающих примеров и улучшить способность модели к генерализации.

Я тестировал разные комбинации аугментаций на валидационной выборке и оставил только те, которые реально повышали точность и устойчивость модели без переобучения. Такой подход позволяет добиться высокой точности детекции даже на сложных и нестандартных изображениях, что особенно важно для реальных дорожных условий.

## Архитектура и технологии
- Backend: Python, Flask, Flask-Login, Flask-SQLAlchemy
- Frontend: HTML5, Bootstrap 5, Jinja2
- База данных: PostgreSQL
- Модель детекции: YOLO (Ultralytics, torch, CUDA) с расширенной аугментацией данных (вращение, сдвиг, масштабирование, флипы, изменение цвета, mosaic, mixup и др.)
- Работа с изображениями и видео: Pillow, OpenCV
- Интеграция с ИИ: GigaChat API

## Установка и запуск
1. Клонируйте репозиторий:
   - `git clone <url-репозитория>`
   - Перейдите в папку проекта: `cd <название-папки-проекта>`
2. Создайте виртуальное окружение:
   - `python -m venv venv`
   - Активируйте окружение:
     - Windows: `venv\Scripts\activate`
     - Linux/Mac: `source venv/bin/activate`
3. Установите зависимости:
   - `pip install -r requirements.txt`
4. Настройте базу данных:
   - Установите PostgreSQL, создайте БД `roads`
   - В файле `config.py` пропишите строку подключения и секретный ключ
5. Получите ключ GigaChat API:
   - Зарегистрируйтесь на платформе Sber AI, получите ключ и добавьте его в `routes.py`
6. Инициализируйте БД:
   - В интерактивном режиме Python выполните:
     ```python
     from app import app, db
     with app.app_context():
         db.create_all()
     ```
7. Запустите приложение:
   - `python app.py`
   - Откройте браузер и перейдите по адресу http://localhost:5000

## Использование
1. Зарегистрируйтесь в системе
2. Загрузите изображение или видео дорожного покрытия
3. Дождитесь результатов анализа
4. Просмотрите аннотированные файлы и текстовые рекомендации
5. Скачайте обработанные файлы и просмотрите историю загрузок

## Структура проекта
```
project/
├── app.py              # Основной файл приложения
├── routes.py           # Маршруты и обработчики
├── models.py           # Модели базы данных
├── detect.py           # Модуль детекции
├── config.py           # Конфигурация
├── requirements.txt    # Зависимости
├── static/             # Статические файлы
│   ├── uploads/        # Загруженные изображения
│   └── results/        # Результаты обработки
├── templates/          # HTML шаблоны
├── yolo.py             # Скрипт обучения YOLO с аугментациями
└── data.yaml           # Конфигурация датасета
```

## Обучение модели (при необходимости)
1. Подготовьте структуру папок для датасета:
   ```
   dataset/
   ├── images/
   │   ├── train/
   │   └── val/
   └── labels/
       ├── train/
       └── val/
   ```
2. Разместите изображения и аннотации в соответствующих папках
3. Отредактируйте файл `data.yaml` (укажите путь к датасету, количество классов и их имена)
4. Запустите обучение с помощью скрипта `yolo.py`:
   - Все основные аугментации уже включены в параметры обучения (вращение, сдвиг, масштабирование, флипы, изменение цвета, mosaic, mixup и др.)
   - Запуск: `python yolo.py`
5. Скопируйте веса модели (`best.pt`) в папку проекта и укажите путь к ним в `detect.py`
